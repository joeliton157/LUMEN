# LUMEN â€“ Local Unified Model for Explainable Neurodiagnosis

LUMEN Ã© uma arquitetura de rede neural explicÃ¡vel desenvolvida para avaliar riscos de doenÃ§as como o cÃ¢ncer a partir de trÃªs domÃ­nios principais: genÃ©tico, ambiental e fisiolÃ³gico (anteriormente denominado "relativÃ­stico"). A proposta central Ã© integrar esses domÃ­nios por meio de sub-redes especializadas com ativaÃ§Ãµes 'softmax', permitindo uma leitura interpretÃ¡vel dos vetores de risco.

---

## ğŸ”¬ VisÃ£o Geral do Projeto

- Modelagem baseada em sub-redes autÃ´nomas por domÃ­nio  
- Vetores intermediÃ¡rios com 'softmax' para interpretaÃ§Ã£o direta  
- IntegraÃ§Ã£o com LLMs locais (Mistral, OpenChat, Zephyr, Deepseek) para explicaÃ§Ã£o textual  
- Comparativo com modelo convencional (baseline) para validaÃ§Ã£o de performance  

---

## ğŸ“Š Resultados Atuais (Base SintÃ©tica - 500k amostras)

| Modelo   | AcurÃ¡cia | AUC    |
|----------|----------|--------|
| Baseline | 86.63%   | 0.9472 |
| LUMEN    | 86.51%   | 0.9474 |

---

## ğŸ“ˆ Explicabilidade (XAI)

O modelo LUMEN gera vetores intermediÃ¡rios que podem ser visualizados por domÃ­nio:

- DomÃ­nio GenÃ©tico: identifica predisposiÃ§Ãµes hereditÃ¡rias  
- DomÃ­nio Ambiental: avalia exposiÃ§Ãµes e influÃªncias do ambiente  
- DomÃ­nio FisiolÃ³gico: representa alteraÃ§Ãµes metabÃ³licas e expressÃµes gÃªnicas  

Esses vetores sÃ£o usados como entrada para um LLM, que gera explicaÃ§Ãµes automÃ¡ticas em linguagem natural.

---

## ğŸ“š Exemplo de SaÃ­da Explicada

> "O risco estimado Ã© de 38.6%. Fatores fisiolÃ³gicos como R2 e R12 mostraram forte influÃªncia, enquanto o domÃ­nio genÃ©tico apresentou predisposiÃ§Ã£o significativa em G2. O padrÃ£o sugere risco moderado com base em interaÃ§Ãµes bioquÃ­micas e heranÃ§a genÃ©tica."

---

## ğŸ“ Estrutura do Projeto

'''
â”œâ”€â”€ data/                 # Dados de entrada (data.csv)
â”œâ”€â”€ models/               # Modelos treinados (lumen.pt)
â”œâ”€â”€ baseline_model.py     # Modelo convencional
â”œâ”€â”€ lumen_model.py        # Arquitetura LUMEN
â”œâ”€â”€ train.py              # Treinamento e validaÃ§Ã£o
â”œâ”€â”€ explain_lumen_llm.py  # IntegraÃ§Ã£o com LLM para XAI
â”œâ”€â”€ lumen_explain.ipynb   # Notebook visual para interpretaÃ§Ã£o
â””â”€â”€ README.md             # DocumentaÃ§Ã£o do projeto
'''

---

## ğŸš€ Como Rodar

### 1. Instale os requisitos
'''
pip install -r requirements.txt
'''

### 2. Treine o modelo
'''
python train.py --model lumen
'''

### 3. Execute a explicaÃ§Ã£o com LLM local (necessÃ¡rio instalar o Ollama e ou rodar via Huggingface Transformers)
'''
python explain_lumen_llm.py
'''

---

## ğŸ“¦ requirements.txt

'''
pandas
scikit-learn
torch
transformers
matplotlib
'''

---

## ğŸ“š LicenÃ§a

Projeto experimental desenvolvido para fins de pesquisa e avaliaÃ§Ã£o. NÃ£o utilizar para diagnÃ³stico real. Direitos reservados ao autor.

---

Desenvolvido por [Joeliton Victor] â€” projeto LUMEN: explicabilidade como aliada da decisÃ£o mÃ©dica.
